{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V9ZFXFfNFNES"
   },
   "source": [
    "**Weather Retrieval and Analysis**\n",
    "\n",
    "\n",
    "PART 1 **\u2013** Setup, Load Dataset, Preprocess, Disable Telemetry, No API Key\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAkuR5CDFDvL"
   },
   "source": [
    "Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VplhjOZ3FEr3",
    "outputId": "2852c8b5-68cb-49e6-c8c0-de52c159bc73"
   },
   "outputs": [],
   "source": [
    "# Install Hugging Face and FAISS\n",
    "!pip install faiss-cpu gradio transformers sentence-transformers --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bJw52NJ3FdXq"
   },
   "source": [
    "Disable Telemetry (No API Prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xS4e3jPO-gf0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Disable telemetry\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfk-qrPSFjdY"
   },
   "source": [
    "Imports and Dataset Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Zi5B_qw_-jMh"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import faiss\n",
    "import numpy as np\n",
    "import gradio as gr\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63Zt9R8EFpkK"
   },
   "source": [
    "Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 327
    },
    "id": "0Fz8kc_r-l6z",
    "outputId": "60a2ee93-7bdb-47d9-df5d-d6e7201768b3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date Time</th>\n",
       "      <th>p (mbar)</th>\n",
       "      <th>T (degC)</th>\n",
       "      <th>Tpot (K)</th>\n",
       "      <th>Tdew (degC)</th>\n",
       "      <th>rh (%)</th>\n",
       "      <th>VPmax (mbar)</th>\n",
       "      <th>VPact (mbar)</th>\n",
       "      <th>VPdef (mbar)</th>\n",
       "      <th>sh (g/kg)</th>\n",
       "      <th>H2OC (mmol/mol)</th>\n",
       "      <th>rho (g/m**3)</th>\n",
       "      <th>wv (m/s)</th>\n",
       "      <th>max. wv (m/s)</th>\n",
       "      <th>wd (deg)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01.01.2009 00:10:00</td>\n",
       "      <td>996.52</td>\n",
       "      <td>-8.02</td>\n",
       "      <td>265.40</td>\n",
       "      <td>-8.90</td>\n",
       "      <td>93.3</td>\n",
       "      <td>3.33</td>\n",
       "      <td>3.11</td>\n",
       "      <td>0.22</td>\n",
       "      <td>1.94</td>\n",
       "      <td>3.12</td>\n",
       "      <td>1307.75</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.75</td>\n",
       "      <td>152.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01.01.2009 00:20:00</td>\n",
       "      <td>996.57</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>265.01</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>93.4</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.89</td>\n",
       "      <td>3.03</td>\n",
       "      <td>1309.80</td>\n",
       "      <td>0.72</td>\n",
       "      <td>1.50</td>\n",
       "      <td>136.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01.01.2009 00:30:00</td>\n",
       "      <td>996.53</td>\n",
       "      <td>-8.51</td>\n",
       "      <td>264.91</td>\n",
       "      <td>-9.31</td>\n",
       "      <td>93.9</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.88</td>\n",
       "      <td>3.02</td>\n",
       "      <td>1310.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.63</td>\n",
       "      <td>171.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01.01.2009 00:40:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.31</td>\n",
       "      <td>265.12</td>\n",
       "      <td>-9.07</td>\n",
       "      <td>94.2</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.08</td>\n",
       "      <td>1309.19</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.50</td>\n",
       "      <td>198.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01.01.2009 00:50:00</td>\n",
       "      <td>996.51</td>\n",
       "      <td>-8.27</td>\n",
       "      <td>265.15</td>\n",
       "      <td>-9.04</td>\n",
       "      <td>94.1</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.08</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.92</td>\n",
       "      <td>3.09</td>\n",
       "      <td>1309.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.63</td>\n",
       "      <td>214.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Date Time  p (mbar)  T (degC)  Tpot (K)  Tdew (degC)  rh (%)  \\\n",
       "0  01.01.2009 00:10:00    996.52     -8.02    265.40        -8.90    93.3   \n",
       "1  01.01.2009 00:20:00    996.57     -8.41    265.01        -9.28    93.4   \n",
       "2  01.01.2009 00:30:00    996.53     -8.51    264.91        -9.31    93.9   \n",
       "3  01.01.2009 00:40:00    996.51     -8.31    265.12        -9.07    94.2   \n",
       "4  01.01.2009 00:50:00    996.51     -8.27    265.15        -9.04    94.1   \n",
       "\n",
       "   VPmax (mbar)  VPact (mbar)  VPdef (mbar)  sh (g/kg)  H2OC (mmol/mol)  \\\n",
       "0          3.33          3.11          0.22       1.94             3.12   \n",
       "1          3.23          3.02          0.21       1.89             3.03   \n",
       "2          3.21          3.01          0.20       1.88             3.02   \n",
       "3          3.26          3.07          0.19       1.92             3.08   \n",
       "4          3.27          3.08          0.19       1.92             3.09   \n",
       "\n",
       "   rho (g/m**3)  wv (m/s)  max. wv (m/s)  wd (deg)  \n",
       "0       1307.75      1.03           1.75     152.3  \n",
       "1       1309.80      0.72           1.50     136.1  \n",
       "2       1310.24      0.19           0.63     171.6  \n",
       "3       1309.19      0.34           0.50     198.0  \n",
       "4       1309.00      0.32           0.63     214.3  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the weather dataset\n",
    "# csv_path = '/content/drive/MyDrive/Colab Notebooks/Projects(AI ML)/jena_climate_2009_2016.csv'  # Uploaded dataset path\n",
    "# df = pd.read_csv(csv_path)\n",
    "\n",
    "csv_path = r\"C:\\Users\\Yeshwanth\\Downloads\\Weather-Retrieval-and-Analysis-main\\Weather-Retrieval-and-Analysis-main\\Weather-Retrieval-Analysis\\DataSet\\jena_climate_2009_2016.csv\\jena_climate_2009_2016.csv\"  # Uploaded dataset path\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# View sample rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Yr3Fn6WF0g8"
   },
   "source": [
    "Convert Rows to Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dKiu05g3-r7U",
    "outputId": "c7ec370a-4ea9-4db7-9fae-dcc8a1bf4cc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime: 01.01.2009 00:10:00, Temperature: -8.02\u00b0C, Humidity: 93.3%, Wind Speed: 1.03 m/s\n"
     ]
    }
   ],
   "source": [
    "# Convert rows into text chunks (for embedding)\n",
    "def row_to_text(row):\n",
    "    return f\"DateTime: {row['Date Time']}, Temperature: {row['T (degC)']}\u00b0C, Humidity: {row['rh (%)']}%, Wind Speed: {row['wv (m/s)']} m/s\"\n",
    "\n",
    "# Apply to a subset for speed (e.g., 10,000 rows)\n",
    "texts = df.head(10000).apply(row_to_text, axis=1).tolist()\n",
    "\n",
    "# Preview one\n",
    "print(texts[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xHH0zotF_eS"
   },
   "source": [
    "PART 2 \u2013 Embeddings + FAISS Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j0PsQtnhGCEu"
   },
   "source": [
    "Load SentenceTransformer Model for Embeddings\n",
    "\n",
    "We\u2019ll use a lightweight yet effective embedding model.\n",
    "\n",
    "\"all-MiniLM-L6-v2\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 498,
     "referenced_widgets": [
      "cc3aee4754fc45bd82aac6bb6306b22c",
      "df707a2c15d841798a1357b343336195",
      "bd88be8db7d840d9940554503c0861d8",
      "d73f7a3834044546b6d6e59f0794cacf",
      "ae06e2aa27a346b9a61b2daa99684dbc",
      "9cafa83aa1e847169a9882d19e04ac87",
      "386b7331106f448790cb12fcf3124943",
      "c150fbe991d44fe39654d67113114a34",
      "7f07e81f67da42239beaf01a9914224b",
      "a69f0b46c0d946d1911ac9e25d430539",
      "6af1f84ce8cc40d59dd12c09b5910224",
      "6db328ef84d148eaae3341ec32e2d066",
      "cefa5cef194c40aa93bfd4cfa5816ce6",
      "1795aebd76db47dbb58f75e58b9ce315",
      "2c1a7cd9ea0a4a19abcf46e62ce83c0f",
      "fac4baa7b47b4d608bf74d3a947539af",
      "818145203ef2400788b6cb2f1d0a6884",
      "94d7951a35c742a681de782691a06f89",
      "36f0f20166ad4913984b680f876764d2",
      "b1fa599229af44d495332b046b4b44d7",
      "4ec5df717cb7409ca5e670d9aaea5a16",
      "9891a63960b644e2943ed35be79ef666",
      "9055417a09104e81bfa58e8c84cddc10",
      "1f805ccc2ad44399ae426580827d6e1c",
      "0c534eb5c34e48329be3dc69768801f6",
      "aa90ddfded534be093b706635b2148db",
      "3e9d2e54cb794cd89f5b3b64ae37c412",
      "2cbea3bcda8b48cb83649973f5dd792a",
      "ab8ceb9a248a48fab3a611d7794b33ca",
      "021e3283e38d49618fe49955a9d0c338",
      "d409bc0b7e5b4c68a61fd270eaa27bfa",
      "e0671efd98164d718e97bbc8f7049302",
      "a481c40e8ed045f996ebc5aef4327764",
      "da5e73309b464142aacb1a53345a0b9b",
      "fd162127c06a49ac9b4152d3e7fffce0",
      "bc11ad560a1145e186ca822b320f76e9",
      "82790aeb9b664d0a8856148214a4513d",
      "bb1fb5aef0a342feaf528cc23e302f59",
      "e139cb7bb98345149f7c6cf878c231dd",
      "e409dad83b554ec39af661aff16e34b8",
      "aa9960e29e5c49e4b2d2c379709bebf2",
      "5e09db87f9a849d7ad72ff7a0f3ecde3",
      "f874fae98e994584bee710f4fe4d394b",
      "3995438f2cb04fa6a2d03eb5efa91e67",
      "dca9a28e4f344172ace9ebfacef0f3d8",
      "78bc1c998fc449379efa5c1aac0c5c34",
      "dd31a0b976bb4dc89b38cfb69ebee464",
      "2a39dd38ad734acd8331b3ddb45c5d40",
      "aa9b45d5c2ee4245a7b3dbc63a768b71",
      "72be3d613c5e48038683f222f0569533",
      "e9d3edfc6d7f450582cf04622a122cd1",
      "403bc41407464a4fa6f1f10f0e6e3351",
      "6fbe130bdc3d44e6abe807e2d0fb09b9",
      "e960575f9b9d4b8ba8f1d0c906eec6fe",
      "1caf14bc6ea640c9bf98aac0bdc4628f",
      "655c6291f5e1479489fbc5588736f4a8",
      "8c01353daa7f42d1b1a8581a30d41036",
      "a8c522c843034a7a9c43a391c81ae7dc",
      "1ba9c560deb940ec9e57e2dbca3c4226",
      "75590a09c2e64b3880b57f12d2c5303b",
      "eff6ae1f48db45e88a1fe54bb7f05781",
      "286a5f8f151f4b9aa98e6479fa609ff3",
      "1b7d8a23daf54a53bf6edaf756ec096f",
      "230271eadbde4b5d8fe2761f094c4962",
      "68bda271c49844c69d32df18608d63a0",
      "a6f6d133b0c04b76bd7ce386d8192dcc",
      "8a7ab85a7ff74a009744bbf912006433",
      "324cf08856f34fb698626fdf61a83dac",
      "04f9c18c3a64437fb787e2a9d2cda7cc",
      "ad1fcaff8f69431493050c58a28931bf",
      "4318959a1e6f4dadac0866a5f473d154",
      "766bbe94c34047e68ef1d4253f3258e8",
      "77866442cdc349afa71203e661e9a758",
      "aad3dc2266574dbb9bc5e3c2dcfd6afe",
      "05d4e59a4aed48eb94c8ab24cb85e048",
      "993f72eee2d0468ca405abbdb27cac16",
      "8006e1f399d04fa9a513506720c5a417",
      "1431a63581aa4f4a98bf21364dec21fd",
      "cb90c3f9bda845d5a1877778feb0c89c",
      "adc382b06b41485d91903f6e99c6a239",
      "69d1c6a4ab164000939c0780f1cdeb94",
      "52c4aa9435c7484aa0c1a9c4e0a03568",
      "9b0614cac7f9472fa4870a12764d1911",
      "99d338527eae458fb2c126f5f4b54e01",
      "a42ed0fa6bbf46ad9cf00693f82dd37a",
      "03caa03a07814fa1aa322717ff5f507e",
      "ccbedeb2b1d04093aa1c438e82261972",
      "f9379fae20944f16b47897d176c4ef00",
      "ad0b7863b704498cbc498bc0e797731c",
      "d07a925b568341d1b075aa4dd84deea0",
      "b5b74935137644be8038bc9e1f52bc95",
      "0dd1063adc384b3d858cc40cd6d687cf",
      "4cf5ca93326c4beaa86e63d6b3384668",
      "b85c1893db85435c8cb21e8ddd9be31d",
      "e5a46c258c854192bba0b19b33e6d84d",
      "1c27bf80ce5c49fbb460aefb671ff145",
      "ffa4d1539bb6473787ac6eed8470637b",
      "17e935db150f4fc88071efbbc5bd63bd",
      "c6179605cb03475bb1cb7d6fe0cda33a",
      "74aa86e0115747a793d34efc5ba48311",
      "2fb515a7af424b74bad0da0865363232",
      "2a2a9e7a53484192aae3343bb3579db3",
      "9d9056a795b446c391ae53f1901820f4",
      "31d49c5899154b4eadbed2d12a88dc26",
      "ce42a92ea4344b44802dcab993909387",
      "be0a810621e74244bd2ac4bf03fc7e85",
      "49f632a5d3d84dd59cf322bb0062a363",
      "2469ac9c84014933a19fdc82bce69614",
      "5668f85da49742228cf75aef3839cf83",
      "620faf3121a14803856ebf09fc5e21e1",
      "740a027f6a15482b92e4fc8bb3c4b298",
      "b116548923d141b7b9f28e7ac8b20ace",
      "bc5d8d2bbb6c4367ac7909b988954252",
      "3d9a53c76fd743efbf0a223712e21a4b",
      "965bb5dc60e14576a70ee28aae342fb6",
      "711bbbcdd8c649579be5b0ace74a664e",
      "d8bc9d4d340b4865ad130fa041ad8dad",
      "468eb580e1cb4970bc1884264c822385",
      "d8257d72fa6943a8be036d8915ae222e",
      "eb4743d614e7434b95182174e4ebaf20",
      "447049ff3290404e94befcdeca8d6b3c"
     ]
    },
    "id": "_N-4uHPF_t7k",
    "outputId": "18301908-69fd-4694-a6d1-a933c241fc62"
   },
   "outputs": [],
   "source": [
    "# Load embedding model (efficient & suitable for Colab)\n",
    "embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pe5dTym0GWRK"
   },
   "source": [
    "Generate Embeddings for Text Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67,
     "referenced_widgets": [
      "e7c36ed5ecfb49029308507e9cc60a94",
      "2ef2fcbcdfda4cbd8a8e4b1de4b6aaeb",
      "ad828a4dea85442698759977cd9a35a6",
      "99b528f87a224f90b3b8a12f271e1649",
      "6810958b6f1143cca742715f6ee4f5ad",
      "c28dc6861b7f4456ba212f22b337b449",
      "a4e3986676f844bb8c99ab2af2b612ad",
      "5480e2c006c340b89acf7b89d6eda8ef",
      "c5cdf7fedde541078e18a497f1c9ce9b",
      "0b3d908f9dde468a842b644f1db384cb",
      "dd6eaaec0b1d42209829efb40f8b3dcf"
     ]
    },
    "id": "q8Qf1DTo_9bd",
    "outputId": "03824b78-6f2a-492c-8d44-85c259c01846"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a390fbd58a9416895ccdaa031743db2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (10000, 384)\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings (batch processing for speed)\n",
    "embeddings = embedder.encode(texts, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# Shape of embeddings\n",
    "print(f\"Embeddings shape: {embeddings.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3CKWgovGc6T"
   },
   "source": [
    "Store Embeddings in FAISS Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "elOdWb7eABQC",
    "outputId": "32d47fce-6fbf-4abd-a628-f95ab6890f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in FAISS index: 10000\n"
     ]
    }
   ],
   "source": [
    "# Create FAISS index\n",
    "embedding_dim = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(embedding_dim)\n",
    "\n",
    "# Add embeddings to the index\n",
    "index.add(embeddings)\n",
    "\n",
    "# Save the mapping between embeddings and original text\n",
    "text_mapping = {i: text for i, text in enumerate(texts)}\n",
    "\n",
    "# Confirm size\n",
    "print(f\"Number of vectors in FAISS index: {index.ntotal}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJUm8wCJGiUB"
   },
   "source": [
    "Retrieval Function\n",
    "\n",
    "This function will:\n",
    "\n",
    "Convert the user query into an embedding.\n",
    "\n",
    "Search FAISS for top-k similar weather data.\n",
    "\n",
    "Return retrieved text chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jpVxyBVUAGHU"
   },
   "outputs": [],
   "source": [
    "def retrieve_similar_chunks(query, k=5):\n",
    "    # Embed the query\n",
    "    query_embedding = embedder.encode([query], convert_to_numpy=True)\n",
    "\n",
    "    # Search FAISS\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "\n",
    "    # Retrieve corresponding text\n",
    "    results = [text_mapping[idx] for idx in indices[0]]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LjzWxYfNAQCd"
   },
   "source": [
    "Test Retrieval Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ky7Sc0ZAKJx",
    "outputId": "baefb37c-bcff-45cc-8df5-6ea5754ad6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DateTime: 10.01.2009 11:10:00, Temperature: -9.49\u00b0C, Humidity: 70.4%, Wind Speed: 0.8 m/s\n",
      "DateTime: 10.01.2009 13:50:00, Temperature: -3.9\u00b0C, Humidity: 60.36%, Wind Speed: 1.18 m/s\n",
      "DateTime: 10.02.2009 20:30:00, Temperature: 1.55\u00b0C, Humidity: 87.5%, Wind Speed: 1.99 m/s\n",
      "DateTime: 10.01.2009 11:40:00, Temperature: -8.39\u00b0C, Humidity: 68.64%, Wind Speed: 0.33 m/s\n",
      "DateTime: 10.01.2009 11:20:00, Temperature: -9.42\u00b0C, Humidity: 68.78%, Wind Speed: 0.66 m/s\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "query = \"What was the weather like on 2009-01-01?\"\n",
    "\n",
    "# Retrieve similar weather chunks\n",
    "results = retrieve_similar_chunks(query)\n",
    "\n",
    "# Display results\n",
    "for res in results:\n",
    "    print(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1edSisZHDn1"
   },
   "source": [
    "PART 3 \u2013 Local LLM Response Generation\n",
    "\n",
    "*   Concatenate the retrieved chunks.\n",
    "*   Use a local LLM to answer your weather query.\n",
    "*   Return the LLM-generated response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q0ixTw0RHTAE"
   },
   "source": [
    " Load the LLM\n",
    "\n",
    " google/flan-t5-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "b0c1f5809b2a4809bda4bf91eb2e8783",
      "10e8bdbf789f401787cbc4de6e2aaab9",
      "e99a8be798a840f2b045187cf8a7596f",
      "b5d8144b22cd4937a5b9551046c8c811",
      "0ac157d387d9439bb5d8c2e85a73e303",
      "3fcf5fa04c3940419a68a3cb2c2907b2",
      "9e2f84f4d3c245e4bb6f91e08982e4c3",
      "c2e904c4bcc64aeea5e557c167b359d2",
      "2c1af102e7004bdc96331b35e1c8e61a",
      "7a1ba7d4417b4923a69165fb63a8b98a",
      "0f874e5157ce441f909af8ac4826c3cd",
      "49b3ce18a31544e0bd8dfd844c36881d",
      "1dcd054af3cd4c5db3676d1eaedea048",
      "6476133e416942a3a40efb006e5e0b2e",
      "65e46c01748041289ce959d175c79863",
      "a2a8dcd4822c4f03a0816f3ab08209cf",
      "4772381cf0c646b99c2621b3b1f7f7eb",
      "c16b7632d8684f48923a50603d207df6",
      "b0dcf2da7ab44d4b9c55b9dfc622024d",
      "63c1f3b6d69149c59d29edbef89a83d9",
      "d0625437d7b543028058e0a9fd5d85df",
      "34fdeea36e8d4cce8bd379895b0c953d",
      "515abb92323e46699f288795b4399009",
      "d8e9e47c75364a9d909a90f150f09905",
      "818d04b09a6c4bcdaa65223c931eb341",
      "db6c52793ea84c69a0c4426e2c8bc15d",
      "19877172143843aa82a7c42fcb2066fe",
      "9bf67309910040398fcd183de578fef6",
      "dc647083cc7146379f0c9660705f2fce",
      "5872146fe9f944e2917a027044f747ac",
      "c3067e32a8cc415db77f19f7a3160c08",
      "5065623d629446c08c351d3bff9d57a0",
      "c02389fef3c846958e86227c338ccf9d",
      "4922d1f7227c41c381ed15665a4c3021",
      "b8736f142ce344aa8b3fbc1b55775ea2",
      "dc5a793d4f4c4d26ad968a28e7fd7449",
      "27d77b22d2be46e196835b51f6e65019",
      "bbe6ae144d534f4fba0c9808946b1fa9",
      "6d09034bad754e218760918bdf64a1cf",
      "e796ba8708ff4192887df46f349c445a",
      "33258d47a437410dab20bcf8b5bdba2e",
      "6000e769eeb046d08e763536eca7941b",
      "6c9444b60bc74b9a8aa7b5db8fc64079",
      "9147a84859fe4c9a95d8f60cb4f8ac14",
      "ee9f3109de80437cb00b6fe7e649b766",
      "759c6ce5d1c34c5986251d80ea72312c",
      "b02967a7b6324b6da988bed05b685b17",
      "2f8e90e59bab4843a1d646cb5f204015",
      "c35b9e6983a0474284e4d1572dab659a",
      "e007c49b082d45dabd237530c3cf82cd",
      "57d7f64abf68442a92673a0e41549c21",
      "4360a7ca6d924fa398c0a7d0ce87efc9",
      "8408cf9817024c76a59ac93983543d5b",
      "721eee664d544adeac96cce0f9901847",
      "60532ba2a38547579a8b29250b71bb6d",
      "d6bfb090b9774480b4f45d207fdd4144",
      "8aef24a6debd4f58a1cd8be0a808a97c",
      "29f314f975e34873b8f50ea73ded7904",
      "e3f5d18c255a41688eaf4b051a54e74f",
      "79f4784dfd174e92b46fa76468b1d92f",
      "a1f97cf52a6d4564ac423296c5e642d8",
      "ff564764b60445758008e0860678a98a",
      "5ceeb973b9df4e8c8265d70beb23ab7c",
      "1f1524588bdc420cbf9581bb8796db41",
      "344284a150ac436ab8469683e3fa7e0b",
      "a60f54ecae414e489f39ce1758f9ff9b",
      "7336c5c7f3d14f2cb924398e6cc199ef",
      "d036341932734c4799b44a894f8ca5e9",
      "647287de1645493191943074aa85cbde",
      "f3d6d634560d405193a2add2e0f41236",
      "15752195f8e34705a23f3d415a3d71c7",
      "4c2e7c9621b74657908cb920265894d1",
      "5bac80f0cc044093b1b932520d372209",
      "f7dd7902156049089af7813669023c89",
      "abbe57b261fd48e9ba8a2ebdc6f7d138",
      "85f5caa6c34649beb521deeb70c69654",
      "b9a01412ae2a4c9f85fa707c400e6798"
     ]
    },
    "id": "h2weAhW9BKX2",
    "outputId": "c6f3b6ed-dfb0-473b-edd3-5508cbda6755"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc2a3d6c4e17426a8eec6e371972d903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Yeshwanth\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Yeshwanth\\.cache\\huggingface\\hub\\models--google--flan-t5-base. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "688c4ace6d164e1f9c227af155523afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "848ff3ec10874817b76eaf9abe726425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e176a88ce4f242eca7d96795316d93c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77893d8514a4492591eb4686a422aaf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96465ccb0ba04e068a853ff4fdd1deb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17786078180a4db1bb9a445092dd2a67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load text generation pipeline (small model for speed)\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "\n",
    "llm_name = \"google/flan-t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(llm_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(llm_name)\n",
    "\n",
    "# Define text generation function\n",
    "def generate_answer(prompt, max_tokens=200):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model.generate(**inputs, max_length=max_tokens)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nan9oeFnHzgy"
   },
   "source": [
    "Combine Retrieval + Generation\n",
    "\n",
    "We will:\n",
    "*   Retrieve relevant weather chunks.\n",
    "*   Construct a prompt.\n",
    "*   Generate the answer using Flan-T5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "SD3iVHsbBq2H"
   },
   "outputs": [],
   "source": [
    "def answer_query(query):\n",
    "    # Step 1: Retrieve\n",
    "    retrieved_chunks = retrieve_similar_chunks(query)\n",
    "\n",
    "    # Step 2: Combine chunks\n",
    "    context = \"\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Step 3: Construct prompt\n",
    "    prompt = f\"\"\"Given the following weather data:\\n{context}\\nAnswer the question: {query}\"\"\"\n",
    "\n",
    "    # Step 4: Generate response\n",
    "    answer = generate_answer(prompt)\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8D5JQMqyB0eJ"
   },
   "source": [
    "\n",
    " Test LLM Response\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j6Sjvi1fBwp0",
    "outputId": "4d30cea1-696f-412a-9a25-01453f2a93b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Response:\n",
      "Windy\n"
     ]
    }
   ],
   "source": [
    "query = \"What was the weather like on 14th January 2009 afternoon?\"\n",
    "response = answer_query(query)\n",
    "\n",
    "print(\"LLM Response:\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bv0XF8hAIQko"
   },
   "source": [
    "PART 4 \u2013 Gradio Web Interface\n",
    "\n",
    "1.   Create a Gradio app for text input + LLM output.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JxMaND7EIzTX"
   },
   "source": [
    "Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 650
    },
    "id": "cNoYPMulCEA1",
    "outputId": "9e050943-644a-426b-bd1a-b84aee39d222"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def gradio_interface_without_plot(query):\n",
    "    retrieved_chunks = retrieve_similar_chunks(query)\n",
    "    response = answer_query(query)\n",
    "    return response\n",
    "\n",
    "gr.Interface(\n",
    "    fn=gradio_interface_without_plot,\n",
    "    inputs=gr.Textbox(label=\"Enter Your Weather Question\"),\n",
    "    outputs=gr.Textbox(label=\"LLM Response\"),\n",
    "    title=\"Weather Predictor using RAG (FAISS + LLM)\",\n",
    "    description=\"Ask about past weather and get insights using RAG (Retrieval-Augmented Generation)!\"\n",
    ").launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFEkFKjE5to5"
   },
   "source": [
    "\"Real-Time Weather vs Historical Climate: Temperature Comparison Using Jena Climate Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 613
    },
    "id": "I8mNI-Qt5lVr",
    "outputId": "338e8cc5-ea55-4d1c-a802-42e66905cac4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* Running on public URL: https://af646fc19bab3964f7.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://af646fc19bab3964f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install requests gradio --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import gradio as gr\n",
    "\n",
    "# Load dataset\n",
    "# df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Projects(AI ML)/jena_climate_2009_2016.csv')\n",
    "df = pd.read_csv(\n",
    "    r\"C:\\Users\\Yeshwanth\\Downloads\\Weather-Retrieval-and-Analysis-main\\Weather-Retrieval-and-Analysis-main\\Weather-Retrieval-Analysis\\DataSet\\jena_climate_2009_2016.csv\\jena_climate_2009_2016.csv\"\n",
    ")\n",
    "\n",
    "df['Date Time'] = pd.to_datetime(df['Date Time'], format='%d.%m.%Y %H:%M:%S')\n",
    "\n",
    "# Filter data for 2009\n",
    "df_2009 = df[df['Date Time'].dt.year == 2009]\n",
    "\n",
    "# OpenWeatherMap API Key\n",
    "API_KEY = \"e2438cd8b6f47cceb53993ecf3731624\"\n",
    "\n",
    "# Get real-time weather\n",
    "def get_current_weather(location):\n",
    "    url = f\"https://api.openweathermap.org/data/2.5/weather?q={location}&appid={API_KEY}&units=metric\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        return {\n",
    "            \"temp\": data['main']['temp'],\n",
    "            \"humidity\": data['main']['humidity'],\n",
    "            \"wind_speed\": data['wind']['speed'],\n",
    "            \"description\": data['weather'][0]['description'].capitalize()\n",
    "        }\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Get 2009 temperature for today's date\n",
    "def get_2009_temp_for_today(df_2009):\n",
    "    today = datetime.now()\n",
    "    target_date_2009 = datetime(2009, today.month, today.day)\n",
    "    filtered = df_2009[df_2009['Date Time'].dt.date == target_date_2009.date()]\n",
    "    if not filtered.empty:\n",
    "        temp_2009 = round(filtered.iloc[0]['T (degC)'], 2)\n",
    "        date_2009 = filtered.iloc[0]['Date Time'].strftime('%d.%m.%Y %H:%M:%S')\n",
    "        return temp_2009, date_2009\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Gradio interface function (No plot)\n",
    "def compare_weather(query, location):\n",
    "    temp_2009, date_2009 = get_2009_temp_for_today(df_2009)\n",
    "    current_weather = get_current_weather(location)\n",
    "\n",
    "    if temp_2009 is None or current_weather is None:\n",
    "        return \"Error retrieving data.\", \"Check dataset or API\"\n",
    "\n",
    "    comparison = f\"\ud83d\udcc5 2009 Date: {date_2009} | \ud83c\udf21\ufe0f Temp: {temp_2009}\u00b0C\\n\"\n",
    "    comparison += f\"\ud83d\udccd Current Temp in {location}: {current_weather['temp']}\u00b0C\\n\"\n",
    "\n",
    "    diff = round(current_weather['temp'] - temp_2009, 2)\n",
    "    if diff > 0:\n",
    "        comparison += f\"Today is {diff}\u00b0C warmer than the same day in 2009.\"\n",
    "    elif diff < 0:\n",
    "        comparison += f\"Today is {abs(diff)}\u00b0C colder than the same day in 2009.\"\n",
    "    else:\n",
    "        comparison += \"Today\u2019s temperature is the same as in 2009!\"\n",
    "\n",
    "    real_time_info = (\n",
    "        f\"Location: {location}, Temperature: {current_weather['temp']}\u00b0C, \"\n",
    "        f\"Humidity: {current_weather['humidity']}%, Wind Speed: {current_weather['wind_speed']} m/s, \"\n",
    "        f\"Weather: {current_weather['description']}\"\n",
    "    )\n",
    "\n",
    "    return comparison, real_time_info\n",
    "\n",
    "# Gradio UI (No plot output)\n",
    "gr.Interface(\n",
    "    fn=compare_weather,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Enter Your Weather Question\"),\n",
    "        gr.Textbox(label=\"Enter City for Real-Time Weather\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        gr.Textbox(label=\"Comparison (2009 vs Today)\"),\n",
    "        gr.Textbox(label=\"Real-Time Weather Data\")\n",
    "    ],\n",
    "    title=\"Weather Intelligence: Historical vs Real-Time\",\n",
    "    description=\"Compare today\u2019s temperature with the same day in 2009 (Jena Climate Dataset).\"\n",
    ").launch(share=True)  # share=True for Colab use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufUuv_BCh1oe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}