{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "43befd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Install required libraries silently\n",
    "!pip install -q transformers faiss-cpu sentence-transformers requests gradio google-genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae1da1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import requests\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import gradio as gr\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "# Import Google GenAI SDK (Handles naming variability)\n",
    "try:\n",
    "    from google import genai\n",
    "except ImportError:\n",
    "    try:\n",
    "        import google.genai as genai\n",
    "    except ImportError:\n",
    "        print(\"Error: The google-genai package is required.\")\n",
    "        sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b3d462a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 1. Configuration and Constants\n",
    "# ====================================================================\n",
    "WEATHER_API_KEY = os.getenv(\"WEATHER_API_KEY\", \"your_weather_api_key_here\")\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\", \"your_gemini_api_key_here\")\n",
    "\n",
    "# OpenWeatherMap 4-day / 3-hour forecast endpoint\n",
    "WEATHER_BASE_URL = \"https://api.openweathermap.org/data/2.5/forecast\"\n",
    "EMBEDDING_MODEL_NAME = 'all-MiniLM-L6-v2'\n",
    "TOP_K_CONTEXT = 3 # Number of relevant documents to retrieve in semantic search\n",
    "FORECAST_DAYS = 4 # Used internally for API call setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a38ba476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# 2. WeatherRAGAssistant Class (RAG Core)\n",
    "# ====================================================================\n",
    "\n",
    "class WeatherRAGAssistant:\n",
    "    \"\"\"Core class handling data fetching, vector indexing (RAG), and LLM generation.\"\"\"\n",
    "\n",
    "    def __init__(self, weather_key: str, gemini_key: str):\n",
    "        \"\"\"Initializes Sentence Transformer (Embedding) and Gemini Client.\"\"\"\n",
    "        try:\n",
    "            self.embed_model = SentenceTransformer(EMBEDDING_MODEL_NAME)\n",
    "            self.gemini_client = genai.Client(api_key=gemini_key)\n",
    "            self.weather_key = weather_key\n",
    "            self.index = None\n",
    "            self.texts = [] # Stores all formatted weather chunks\n",
    "            print(f\"\u2705 RAG Assistant initialized with embedding model: {EMBEDDING_MODEL_NAME}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Failed to initialize RAG components: {e}\")\n",
    "            raise\n",
    "\n",
    "    def fetch_and_index_weather(self, location: str, days: int = FORECAST_DAYS):\n",
    "        \"\"\"Fetches OpenWeatherMap data, formats it into daily summaries, and builds the FAISS index.\"\"\"\n",
    "        print(f\"\\n\u2699\ufe0f Fetching weather for {location} ({days} days)...\")\n",
    "        try:\n",
    "            params = {\n",
    "                \"q\": location,\n",
    "                \"appid\": self.weather_key,\n",
    "                \"units\": \"metric\" # Celsius\n",
    "            }\n",
    "            response = requests.get(WEATHER_BASE_URL, params=params, timeout=10)\n",
    "            print(f\"[DEBUG] API Request URL: {response.url}\")\n",
    "            response.raise_for_status() # Raises HTTPError for 4xx/5xx status codes\n",
    "            api_response = response.json()\n",
    "            self.texts = self._format_weather_data(api_response)\n",
    "            self._build_faiss_index(self.texts)\n",
    "            print(f\"\u2705 Index built successfully for {location}. Documents indexed: {len(self.texts)}\")\n",
    "            print(f\"[DEBUG] Indexed Texts Sample: {self.texts[0]} ... {self.texts[-1]}\")\n",
    "            return api_response, self.texts\n",
    "\n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            status_code = e.response.status_code\n",
    "            if status_code == 404:\n",
    "                error_msg = \"Location not found. Please check spelling or use City, Country format (e.g., Paris, FR).\"\n",
    "            elif status_code == 401:\n",
    "                error_msg = \"Invalid API Key. Please check your OpenWeatherMap key.\"\n",
    "            else:\n",
    "                error_msg = f\"API Request Failed: HTTP {status_code}.\"\n",
    "\n",
    "            print(f\"\u274c API Request Failed for {location}: {error_msg}\")\n",
    "            self.index = None\n",
    "            self.texts = []\n",
    "            return None, None\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Data processing or Indexing Failed: {e}\")\n",
    "            self.index = None\n",
    "            self.texts = []\n",
    "            return None, None\n",
    "\n",
    "    def _format_weather_data(self, api_response: dict) -> list[str]:\n",
    "        \"\"\"Converts raw 3-hour OWM forecast chunks into daily max/min summaries.\"\"\"\n",
    "        daily_data = {}\n",
    "\n",
    "        # Iterate over the 3-hour forecasts to aggregate daily values\n",
    "        for three_hour_forecast in api_response.get('list', []):\n",
    "            timestamp = three_hour_forecast['dt']\n",
    "            date_str = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d')\n",
    "\n",
    "            # Extract main metrics\n",
    "            temp_max = three_hour_forecast['main']['temp_max']\n",
    "            temp_min = three_hour_forecast['main']['temp_min']\n",
    "            description = three_hour_forecast['weather'][0]['description']\n",
    "            rain = three_hour_forecast.get('rain', {}).get('3h', 0)\n",
    "\n",
    "            if date_str not in daily_data:\n",
    "                daily_data[date_str] = {\n",
    "                    'temp_max': temp_max, 'temp_min': temp_min,\n",
    "                    'description_list': set(), 'rain_total': 0.0\n",
    "                }\n",
    "\n",
    "            # Update min/max for the day\n",
    "            daily_data[date_str]['temp_max'] = max(daily_data[date_str]['temp_max'], temp_max)\n",
    "            daily_data[date_str]['temp_min'] = min(daily_data[date_str]['temp_min'], temp_min)\n",
    "            daily_data[date_str]['description_list'].add(description)\n",
    "            daily_data[date_str]['rain_total'] += rain\n",
    "\n",
    "        texts = []\n",
    "        for date, data in daily_data.items():\n",
    "            descriptions = \", \".join(sorted(list(data['description_list'])))\n",
    "            rain_total_rounded = round(data['rain_total'], 2)\n",
    "\n",
    "            texts.append(\n",
    "                f\"Date: {date}, Max Temp: {round(data['temp_max'], 1)}\u00b0C, Min Temp: {round(data['temp_min'], 1)}\u00b0C, Total Rain: {rain_total_rounded}mm, Conditions: {descriptions}\"\n",
    "            )\n",
    "\n",
    "        texts.sort() # Ensure chronological order\n",
    "        return texts\n",
    "\n",
    "    def _build_faiss_index(self, texts: list[str]):\n",
    "        \"\"\"Converts text chunks into embeddings and initializes a FAISS vector index.\"\"\"\n",
    "        if not texts:\n",
    "            self.index = None\n",
    "            raise ValueError(\"Cannot build index: Text list is empty.\")\n",
    "\n",
    "        embeddings = self.embed_model.encode(texts, convert_to_numpy=True)\n",
    "        embeddings = np.ascontiguousarray(embeddings.astype('float32'))\n",
    "\n",
    "        d = embeddings.shape[1]\n",
    "        self.index = faiss.IndexFlatL2(d) # L2 (Euclidean) distance index\n",
    "        self.index.add(embeddings)\n",
    "\n",
    "    def search_index(self, query: str) -> list[str]:\n",
    "        \"\"\"Searches the vector index for the top-K most relevant chunks to the query.\"\"\"\n",
    "        if self.index is None or not self.texts:\n",
    "            print(\"\u26a0\ufe0f Index not built. Cannot search.\")\n",
    "            return []\n",
    "\n",
    "        try:\n",
    "            query_vec = self.embed_model.encode([query], convert_to_numpy=True).astype('float32')\n",
    "            D, I = self.index.search(query_vec, TOP_K_CONTEXT)\n",
    "\n",
    "            context = [self.texts[i] for i in I[0] if 0 <= i < len(self.texts)]\n",
    "            print(f\"\u2705 Retrieved {len(context)} context chunks.\")\n",
    "            print(f\"[DEBUG] Retrieved Context: {context}\")\n",
    "            return context\n",
    "        except Exception as e:\n",
    "            print(f\"\u274c Error during index search: {e}\")\n",
    "            return []\n",
    "\n",
    "    def generate_response(self, user_query: str, context: list[str]) -> str:\n",
    "        \"\"\"Sends the question and retrieved context to the Gemini LLM for final answer generation.\"\"\"\n",
    "        if not context:\n",
    "            return \"I could not find relevant weather data to answer your question.\"\n",
    "\n",
    "        # Generic prompt structure used for non-date based queries\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful and concise weather assistant.\n",
    "        Use the following retrieved weather data (Context) to answer the user's Question clearly and concisely.\n",
    "\n",
    "        Context:\n",
    "        ---\n",
    "        {'\\n'.join(context)}\n",
    "        ---\n",
    "\n",
    "        Question: {user_query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.gemini_client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=prompt\n",
    "            )\n",
    "            return response.text.strip()\n",
    "        except Exception as e:\n",
    "            print(f\"[DEBUG] LLM API Error: {e}\")\n",
    "            return f\"\u274c Gemini API Error: Could not generate response. Details: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12955432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 RAG Assistant initialized with embedding model: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# 3. Gradio Interface Logic and State Management (RAG Pipeline)\n",
    "# ====================================================================\n",
    "\n",
    "# Initialize the RAG Assistant (Global State)\n",
    "assistant = WeatherRAGAssistant(WEATHER_API_KEY, GEMINI_API_KEY)\n",
    "\n",
    "initial_location_texts = []\n",
    "FORECAST_DAYS_DISPLAY = 5\n",
    "INITIAL_PROMPT = f\"Enter city name and country code (e.g., Paris, FR) and click 'Refresh Data' to load the {FORECAST_DAYS_DISPLAY}-day forecast.\"\n",
    "\n",
    "def update_location_and_index(new_location: str):\n",
    "    \"\"\"Refreshes weather data from the API and rebuilds the entire FAISS index.\"\"\"\n",
    "    global initial_location_texts\n",
    "\n",
    "    clean_location = new_location.strip()\n",
    "\n",
    "    if \",\" not in clean_location:\n",
    "        initial_location_texts = []\n",
    "        return \"\u26a0\ufe0f Please enter location in 'City, Country' format (e.g., Tokyo, JP).\"\n",
    "\n",
    "    _, initial_location_texts = assistant.fetch_and_index_weather(location=clean_location)\n",
    "\n",
    "    if initial_location_texts:\n",
    "        return f\"Weather data for {clean_location} ({len(initial_location_texts)} days) loaded and indexed. Ready to answer!\"\n",
    "    else:\n",
    "        initial_location_texts = []\n",
    "        return f\"\u274c Failed to load weather data for {clean_location}. Check city spelling, country code, or API status/key.\"\n",
    "\n",
    "\n",
    "def get_target_date_string(user_query: str) -> str | None:\n",
    "    \"\"\"Helper function to convert relative time (Today, Tomorrow, Friday) into YYYY-MM-DD format.\"\"\"\n",
    "\n",
    "    query_lower = user_query.lower()\n",
    "    current_time = datetime.now()\n",
    "    target_date = None\n",
    "\n",
    "    day_mapping = {\n",
    "        'today': 0,\n",
    "        'tomorrow': 1,\n",
    "        'day after tomorrow': 2,\n",
    "    }\n",
    "\n",
    "    # 1. Check Day Names (e.g., 'friday')\n",
    "    current_weekday = current_time.weekday()\n",
    "    day_names = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "\n",
    "    for i in range(7):\n",
    "        target_day_index = (current_weekday + i) % 7\n",
    "        if day_names[target_day_index] in query_lower:\n",
    "            target_date = current_time + timedelta(days=i)\n",
    "            print(f\"[DEBUG] Matched Day Name: {day_names[target_day_index]}, Target Date: {target_date.strftime('%Y-%m-%d')}\")\n",
    "            break\n",
    "\n",
    "    # 2. Check Relative Terms (e.g., 'today', 'tomorrow') - Overrides Day Names\n",
    "    for term, days_delta in day_mapping.items():\n",
    "        if term in query_lower:\n",
    "            target_date = current_time + timedelta(days=days_delta)\n",
    "            print(f\"[DEBUG] Matched Relative Term: {term}, Target Date: {target_date.strftime('%Y-%m-%d')}\")\n",
    "            break\n",
    "\n",
    "    if target_date:\n",
    "        return target_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"[DEBUG] No specific date term found in query. Defaulting to Semantic Search Path.\")\n",
    "    return None\n",
    "\n",
    "\n",
    "def answer_weather_query(user_query: str):\n",
    "    \"\"\"Main function that directs the query to either strict date filtering or semantic search.\"\"\"\n",
    "    if not initial_location_texts:\n",
    "        return \"Please load the weather data first by entering a city and clicking 'Refresh Data'.\"\n",
    "\n",
    "\n",
    "    target_date_str = get_target_date_string(user_query)\n",
    "\n",
    "    if target_date_str:\n",
    "        # --- PATH A: DATE-BASED QUERY (STRICT FILTERING + Recommendation) ---\n",
    "        print(\"[DEBUG] Path A: Executing STRICT DATE FILTERING.\")\n",
    "\n",
    "        # 1. Strict Filtering: Find the EXACT string for the target date.\n",
    "        target_data = None\n",
    "        for text in initial_location_texts:\n",
    "            if target_date_str in text:\n",
    "                target_data = text\n",
    "                break\n",
    "\n",
    "        if target_data is None:\n",
    "            print(f\"[DEBUG] Target Data NOT FOUND in index for date: {target_date_str}\")\n",
    "            return f\"The forecast data for {target_date_str} is not available in the loaded {len(initial_location_texts)}-day forecast range.\"\n",
    "\n",
    "        print(f\"[DEBUG] Target Data FOUND: {target_data}\")\n",
    "\n",
    "        # 2. Final LLM Prompt Construction (Forced Recommendation)\n",
    "        final_context = f\"The verified weather data for {target_date_str} is: {target_data}\"\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "        You are a weather expert. Your task is to provide the requested information and a recommendation SOLELY based on the VERIFIED WEATHER DATA below.\n",
    "\n",
    "        ---\n",
    "        VERIFIED WEATHER DATA FOR {target_date_str}:\n",
    "        {final_context}\n",
    "        ---\n",
    "\n",
    "        QUESTION: What is the Max/Min temperature and what should the user bring (umbrella, etc.)?\n",
    "\n",
    "        ANSWER FORMAT:\n",
    "        1. State the Max and Min temperature.\n",
    "        2. Provide a recommendation. Recommend bringing an umbrella or raincoat if the 'Conditions' mention rain, drizzle, or shower OR if 'Total Rain' is greater than 0.0 mm. Otherwise, recommend based on temperature or general clouds.\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "        context_for_llm = [final_context]\n",
    "\n",
    "    else:\n",
    "        # --- PATH B: SEMANTIC QUERY (VECTOR SEARCH) ---\n",
    "        print(\"[DEBUG] Path B: Executing SEMANTIC VECTOR SEARCH.\")\n",
    "\n",
    "        # 1. Retrieval: Use vector search for general or vague questions.\n",
    "        context_for_llm = assistant.search_index(user_query)\n",
    "\n",
    "        if not context_for_llm:\n",
    "            return \"I found no relevant weather information for your general query.\"\n",
    "\n",
    "        # 2. General Prompt (Original prompt structure)\n",
    "        prompt = f\"\"\"\n",
    "        You are a helpful and concise weather assistant.\n",
    "        Use the following retrieved weather data (Context) to answer the user's Question clearly and concisely.\n",
    "\n",
    "        Context:\n",
    "        ---\n",
    "        {'\\n'.join(context_for_llm)}\n",
    "        ---\n",
    "\n",
    "        Question: {user_query}\n",
    "\n",
    "        Answer:\n",
    "        \"\"\"\n",
    "\n",
    "    print(f\"[DEBUG] Final Context Sent to LLM (Count: {len(context_for_llm)}): {context_for_llm}\")\n",
    "    # 3. Execution\n",
    "    try:\n",
    "        response = assistant.gemini_client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\",\n",
    "            contents=prompt\n",
    "        )\n",
    "        print(f\"[DEBUG] LLM Response Received. Length: {len(response.text)}\")\n",
    "        return response.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[DEBUG] LLM API Error: {e}\")\n",
    "        return f\"\u274c Gemini API Error: Could not generate response. Details: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19adc782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 App initialized. Waiting for user to select location and refresh data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yeshwanth\\AppData\\Local\\Temp\\ipykernel_24368\\492362544.py:13: UserWarning: The parameters have been moved from the Blocks constructor to the launch() method in Gradio 6.0: theme. Please pass these parameters to launch() instead.\n",
      "  with gr.Blocks(title=\"Weather RAG Assistant\", theme=theme) as demo:\n"
     ]
    }
   ],
   "source": [
    "# ====================================================================\n",
    "# 4. Gradio UI Layout\n",
    "# ====================================================================\n",
    "\n",
    "print(\"\ud83d\ude80 App initialized. Waiting for user to select location and refresh data...\")\n",
    "\n",
    "# Define theme\n",
    "theme = gr.themes.Soft(\n",
    "    primary_hue=\"blue\",\n",
    "    secondary_hue=\"slate\",\n",
    ")\n",
    "\n",
    "with gr.Blocks(title=\"Weather RAG Assistant\", theme=theme) as demo:\n",
    "    gr.Markdown(\n",
    "        f\"\"\"\n",
    "        <div style='text-align: center; margin-bottom: 2rem;'>\n",
    "            <h1 style='font-size: 2rem; margin-bottom: 0px;'>\ud83c\udf24\ufe0f Enhanced Weather Assistant</h1>\n",
    "            <p style='font-size: 1.1rem; color: #666;'>Powered by OpenWeatherMap & Gemini-2.5</p>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "    )\n",
    "\n",
    "    with gr.Group():\n",
    "        with gr.Row(variant=\"panel\"):\n",
    "            location_input = gr.Textbox(\n",
    "                label=\"\ud83d\udccd Set Location\",\n",
    "                placeholder=\"e.g., Hyderabad, IN (City, Country Code)\",\n",
    "                scale=4,\n",
    "                info=\"Enter City and Country Code\"\n",
    "            )\n",
    "            refresh_button = gr.Button(\"\ud83d\udd04 Load Data\", variant=\"primary\", scale=1)\n",
    "\n",
    "    with gr.Accordion(\"\ud83d\udcdd System Logs & Status\", open=False):\n",
    "        status_output = gr.Textbox(\n",
    "            show_label=False,\n",
    "            value=INITIAL_PROMPT,\n",
    "            interactive=False,\n",
    "            lines=2,\n",
    "            max_lines=5\n",
    "        )\n",
    "\n",
    "    gr.Markdown(\"### \ud83d\udcac Ask about the weather\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=1):\n",
    "            query_input = gr.Textbox(\n",
    "                label=\"Your Question\",\n",
    "                placeholder=\"e.g., Is it raining tomorrow?\",\n",
    "                lines=3,\n",
    "                show_label=False\n",
    "            )\n",
    "            gr.Examples(\n",
    "                examples=[\n",
    "                    [\"What is the temperature tomorrow?\"],\n",
    "                    [\"Will it rain this weekend?\"],\n",
    "                    [\"Do I need an umbrella on Friday?\"]\n",
    "                ],\n",
    "                inputs=query_input\n",
    "            )\n",
    "            submit_button = gr.Button(\"\u2728 Get Answer\", variant=\"primary\")\n",
    "\n",
    "        with gr.Column(scale=1):\n",
    "            answer_output = gr.Textbox(\n",
    "                label=\"Assistant Response\",\n",
    "                lines=10,\n",
    "                interactive=False,\n",
    "            )\n",
    "\n",
    "    gr.Markdown(\n",
    "        \"<div style='text-align: right; font-size: 0.8em; color: gray;'>\"\n",
    "        \"RAG powered by Sentence-Transformers & Gemini-2.5-flash\"\n",
    "        \"</div>\"\n",
    "    )\n",
    "\n",
    "    # Event Handlers\n",
    "    location_input.submit(fn=update_location_and_index, inputs=[location_input], outputs=[status_output])\n",
    "    refresh_button.click(fn=update_location_and_index, inputs=[location_input], outputs=[status_output])\n",
    "    \n",
    "    submit_button.click(fn=answer_weather_query, inputs=[query_input], outputs=[answer_output])\n",
    "    query_input.submit(fn=answer_weather_query, inputs=[query_input], outputs=[answer_output])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "283630cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u2699\ufe0f Fetching weather for Hyderabad,IN (4 days)...\n",
      "[DEBUG] API Request URL: https://api.openweathermap.org/data/2.5/forecast?q=Hyderabad%2CIN&appid=ee7f62a6de9b3680551df53cea16471e&units=metric\n",
      "\u2705 Index built successfully for Hyderabad,IN. Documents indexed: 6\n",
      "[DEBUG] Indexed Texts Sample: Date: 2026-01-07, Max Temp: 26.6\u00b0C, Min Temp: 18.3\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, clear sky, few clouds, scattered clouds ... Date: 2026-01-12, Max Temp: 19.1\u00b0C, Min Temp: 16.4\u00b0C, Total Rain: 0.0mm, Conditions: clear sky\n",
      "[DEBUG] Matched Relative Term: tomorrow, Target Date: 2026-01-08\n",
      "[DEBUG] Path A: Executing STRICT DATE FILTERING.\n",
      "[DEBUG] Target Data FOUND: Date: 2026-01-08, Max Temp: 26.5\u00b0C, Min Temp: 15.1\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, clear sky, scattered clouds\n",
      "[DEBUG] Final Context Sent to LLM (Count: 1): ['The verified weather data for 2026-01-08 is: Date: 2026-01-08, Max Temp: 26.5\u00b0C, Min Temp: 15.1\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, clear sky, scattered clouds']\n",
      "[DEBUG] LLM Response Received. Length: 209\n",
      "[DEBUG] No specific date term found in query. Defaulting to Semantic Search Path.\n",
      "[DEBUG] Path B: Executing SEMANTIC VECTOR SEARCH.\n",
      "\u2705 Retrieved 3 context chunks.\n",
      "[DEBUG] Retrieved Context: ['Date: 2026-01-11, Max Temp: 25.4\u00b0C, Min Temp: 16.4\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds, scattered clouds', 'Date: 2026-01-10, Max Temp: 27.7\u00b0C, Min Temp: 16.1\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds, scattered clouds', 'Date: 2026-01-09, Max Temp: 26.7\u00b0C, Min Temp: 15.8\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds']\n",
      "[DEBUG] Final Context Sent to LLM (Count: 3): ['Date: 2026-01-11, Max Temp: 25.4\u00b0C, Min Temp: 16.4\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds, scattered clouds', 'Date: 2026-01-10, Max Temp: 27.7\u00b0C, Min Temp: 16.1\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds, scattered clouds', 'Date: 2026-01-09, Max Temp: 26.7\u00b0C, Min Temp: 15.8\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds']\n",
      "[DEBUG] LLM Response Received. Length: 140\n",
      "[DEBUG] Matched Day Name: friday, Target Date: 2026-01-09\n",
      "[DEBUG] Path A: Executing STRICT DATE FILTERING.\n",
      "[DEBUG] Target Data FOUND: Date: 2026-01-09, Max Temp: 26.7\u00b0C, Min Temp: 15.8\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds\n",
      "[DEBUG] Final Context Sent to LLM (Count: 1): ['The verified weather data for 2026-01-09 is: Date: 2026-01-09, Max Temp: 26.7\u00b0C, Min Temp: 15.8\u00b0C, Total Rain: 0.0mm, Conditions: broken clouds, overcast clouds']\n",
      "[DEBUG] LLM Response Received. Length: 291\n"
     ]
    }
   ],
   "source": [
    " demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c989c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}